# Data Configuration
data:
  train_size: 0.1  # 10% of the data
  batch_size: 64   # Smaller batch size for better generalization
  num_workers: 4
  transform:
    normalize_mean: 0.5
    normalize_std: 0.5
  pin_memory: true

# Model Architecture
model:
  input_size: 784
  hidden_dims: [128]  # Single hidden layer for stability
  output_size: 10
  dropout_rate: 0.2   # Moderate dropout
  use_batch_norm: true
  prior_std: 0.1     # Standard prior

# Training Parameters
training:
  simplenn:
    epochs: 75
    learning_rate: 0.01
  sgld:
    epochs: 2000
    learning_rate: 0.005    # Slightly higher learning rate for better exploration
    noise_std: 0.001       # Increased noise for better sampling
    temperature: 1.0       # Standard temperature for proper sampling
    target_samples: 10

# Evaluation
evaluation:
  num_bins: 15
  device: "cuda"

# Random Seed
random_seed: 42 